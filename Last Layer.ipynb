{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_weight_layer_two_pre = pd.read_csv(\"results/rr_s_weight_pre_3.csv\").to_numpy()\n",
    "rr_weight_layer_two_post = pd.read_csv(\"results/rr_s_weight_post_3.csv\").to_numpy()\n",
    "ss_weight_layer_two_pre = pd.read_csv(\"results/ss_s_weight_pre_3.csv\").to_numpy()\n",
    "ss_weight_layer_two_post = pd.read_csv(\"results/ss_s_weight_post_3.csv\").to_numpy()\n",
    "rr_footprint = rr_weight_layer_two_post - rr_weight_layer_two_pre\n",
    "ss_footprint = ss_weight_layer_two_post - ss_weight_layer_two_pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 255)\n"
     ]
    }
   ],
   "source": [
    "pool = nn.MaxPool1d(3, stride=2)\n",
    "pooled_rr_footprint = pool(torch.from_numpy(rr_footprint))\n",
    "print(pooled_rr_footprint.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the dataset\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=512, out_features=255, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=255, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(512,255),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(255, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.410338  [   64/60000]\n",
      "loss: 2.300101  [ 6464/60000]\n",
      "loss: 2.298646  [12864/60000]\n",
      "loss: 2.293285  [19264/60000]\n",
      "loss: 2.268168  [25664/60000]\n",
      "loss: 2.283952  [32064/60000]\n",
      "loss: 2.275866  [38464/60000]\n",
      "loss: 2.258720  [44864/60000]\n",
      "loss: 2.258068  [51264/60000]\n",
      "loss: 2.270478  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 20.2%, Avg loss: 2.251863 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.257909  [   64/60000]\n",
      "loss: 2.246567  [ 6464/60000]\n",
      "loss: 2.235643  [12864/60000]\n",
      "loss: 2.229307  [19264/60000]\n",
      "loss: 2.168821  [25664/60000]\n",
      "loss: 2.185651  [32064/60000]\n",
      "loss: 2.148215  [38464/60000]\n",
      "loss: 2.119588  [44864/60000]\n",
      "loss: 2.077099  [51264/60000]\n",
      "loss: 2.046587  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 37.4%, Avg loss: 2.044736 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.058706  [   64/60000]\n",
      "loss: 2.017439  [ 6464/60000]\n",
      "loss: 1.973233  [12864/60000]\n",
      "loss: 1.953409  [19264/60000]\n",
      "loss: 1.806508  [25664/60000]\n",
      "loss: 1.846423  [32064/60000]\n",
      "loss: 1.774096  [38464/60000]\n",
      "loss: 1.757577  [44864/60000]\n",
      "loss: 1.708149  [51264/60000]\n",
      "loss: 1.670433  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 1.692378 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.740566  [   64/60000]\n",
      "loss: 1.683686  [ 6464/60000]\n",
      "loss: 1.650130  [12864/60000]\n",
      "loss: 1.639712  [19264/60000]\n",
      "loss: 1.524719  [25664/60000]\n",
      "loss: 1.593746  [32064/60000]\n",
      "loss: 1.525350  [38464/60000]\n",
      "loss: 1.507184  [44864/60000]\n",
      "loss: 1.491578  [51264/60000]\n",
      "loss: 1.445483  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 1.447662 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.516734  [   64/60000]\n",
      "loss: 1.453044  [ 6464/60000]\n",
      "loss: 1.386425  [12864/60000]\n",
      "loss: 1.398260  [19264/60000]\n",
      "loss: 1.314739  [25664/60000]\n",
      "loss: 1.369776  [32064/60000]\n",
      "loss: 1.316206  [38464/60000]\n",
      "loss: 1.275440  [44864/60000]\n",
      "loss: 1.306806  [51264/60000]\n",
      "loss: 1.251918  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 1.240255 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.313550  [   64/60000]\n",
      "loss: 1.263139  [ 6464/60000]\n",
      "loss: 1.161642  [12864/60000]\n",
      "loss: 1.232024  [19264/60000]\n",
      "loss: 1.153330  [25664/60000]\n",
      "loss: 1.208886  [32064/60000]\n",
      "loss: 1.183960  [38464/60000]\n",
      "loss: 1.125366  [44864/60000]\n",
      "loss: 1.189097  [51264/60000]\n",
      "loss: 1.132499  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 1.115271 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.190071  [   64/60000]\n",
      "loss: 1.150746  [ 6464/60000]\n",
      "loss: 1.023081  [12864/60000]\n",
      "loss: 1.131149  [19264/60000]\n",
      "loss: 1.042932  [25664/60000]\n",
      "loss: 1.107964  [32064/60000]\n",
      "loss: 1.102346  [38464/60000]\n",
      "loss: 1.032929  [44864/60000]\n",
      "loss: 1.108332  [51264/60000]\n",
      "loss: 1.054451  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 1.034622 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.106204  [   64/60000]\n",
      "loss: 1.078282  [ 6464/60000]\n",
      "loss: 0.929944  [12864/60000]\n",
      "loss: 1.060754  [19264/60000]\n",
      "loss: 0.962525  [25664/60000]\n",
      "loss: 1.034581  [32064/60000]\n",
      "loss: 1.042370  [38464/60000]\n",
      "loss: 0.969663  [44864/60000]\n",
      "loss: 1.044381  [51264/60000]\n",
      "loss: 0.994708  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 0.974497 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.036495  [   64/60000]\n",
      "loss: 1.021382  [ 6464/60000]\n",
      "loss: 0.859000  [12864/60000]\n",
      "loss: 1.005656  [19264/60000]\n",
      "loss: 0.901754  [25664/60000]\n",
      "loss: 0.974697  [32064/60000]\n",
      "loss: 0.992940  [38464/60000]\n",
      "loss: 0.922459  [44864/60000]\n",
      "loss: 0.989461  [51264/60000]\n",
      "loss: 0.943948  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.925323 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.973403  [   64/60000]\n",
      "loss: 0.971388  [ 6464/60000]\n",
      "loss: 0.800354  [12864/60000]\n",
      "loss: 0.959149  [19264/60000]\n",
      "loss: 0.855191  [25664/60000]\n",
      "loss: 0.922982  [32064/60000]\n",
      "loss: 0.949705  [38464/60000]\n",
      "loss: 0.884728  [44864/60000]\n",
      "loss: 0.940080  [51264/60000]\n",
      "loss: 0.898527  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.882700 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.914865  [   64/60000]\n",
      "loss: 0.925266  [ 6464/60000]\n",
      "loss: 0.748629  [12864/60000]\n",
      "loss: 0.917799  [19264/60000]\n",
      "loss: 0.818844  [25664/60000]\n",
      "loss: 0.876735  [32064/60000]\n",
      "loss: 0.910571  [38464/60000]\n",
      "loss: 0.852551  [44864/60000]\n",
      "loss: 0.894464  [51264/60000]\n",
      "loss: 0.856911  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.844178 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.859976  [   64/60000]\n",
      "loss: 0.881825  [ 6464/60000]\n",
      "loss: 0.700439  [12864/60000]\n",
      "loss: 0.880008  [19264/60000]\n",
      "loss: 0.789383  [25664/60000]\n",
      "loss: 0.833825  [32064/60000]\n",
      "loss: 0.874630  [38464/60000]\n",
      "loss: 0.823572  [44864/60000]\n",
      "loss: 0.851954  [51264/60000]\n",
      "loss: 0.818670  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.808537 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.808298  [   64/60000]\n",
      "loss: 0.840933  [ 6464/60000]\n",
      "loss: 0.654192  [12864/60000]\n",
      "loss: 0.845584  [19264/60000]\n",
      "loss: 0.764329  [25664/60000]\n",
      "loss: 0.792818  [32064/60000]\n",
      "loss: 0.841913  [38464/60000]\n",
      "loss: 0.796836  [44864/60000]\n",
      "loss: 0.813032  [51264/60000]\n",
      "loss: 0.784319  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.775783 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.760108  [   64/60000]\n",
      "loss: 0.803509  [ 6464/60000]\n",
      "loss: 0.610310  [12864/60000]\n",
      "loss: 0.815286  [19264/60000]\n",
      "loss: 0.742322  [25664/60000]\n",
      "loss: 0.753870  [32064/60000]\n",
      "loss: 0.812945  [38464/60000]\n",
      "loss: 0.772641  [44864/60000]\n",
      "loss: 0.779090  [51264/60000]\n",
      "loss: 0.754856  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.746814 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.716396  [   64/60000]\n",
      "loss: 0.771076  [ 6464/60000]\n",
      "loss: 0.570718  [12864/60000]\n",
      "loss: 0.790006  [19264/60000]\n",
      "loss: 0.722912  [25664/60000]\n",
      "loss: 0.718566  [32064/60000]\n",
      "loss: 0.787981  [38464/60000]\n",
      "loss: 0.751769  [44864/60000]\n",
      "loss: 0.751469  [51264/60000]\n",
      "loss: 0.730778  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.722434 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.678220  [   64/60000]\n",
      "loss: 0.744664  [ 6464/60000]\n",
      "loss: 0.537275  [12864/60000]\n",
      "loss: 0.769845  [19264/60000]\n",
      "loss: 0.705928  [25664/60000]\n",
      "loss: 0.688390  [32064/60000]\n",
      "loss: 0.766563  [38464/60000]\n",
      "loss: 0.734510  [44864/60000]\n",
      "loss: 0.730418  [51264/60000]\n",
      "loss: 0.711548  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.702568 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.645963  [   64/60000]\n",
      "loss: 0.724122  [ 6464/60000]\n",
      "loss: 0.510467  [12864/60000]\n",
      "loss: 0.753879  [19264/60000]\n",
      "loss: 0.691120  [25664/60000]\n",
      "loss: 0.663587  [32064/60000]\n",
      "loss: 0.747832  [38464/60000]\n",
      "loss: 0.720428  [44864/60000]\n",
      "loss: 0.715037  [51264/60000]\n",
      "loss: 0.696007  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.686407 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.619212  [   64/60000]\n",
      "loss: 0.708421  [ 6464/60000]\n",
      "loss: 0.489492  [12864/60000]\n",
      "loss: 0.740763  [19264/60000]\n",
      "loss: 0.678202  [25664/60000]\n",
      "loss: 0.643375  [32064/60000]\n",
      "loss: 0.731042  [38464/60000]\n",
      "loss: 0.708800  [44864/60000]\n",
      "loss: 0.703961  [51264/60000]\n",
      "loss: 0.683008  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.672974 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.597122  [   64/60000]\n",
      "loss: 0.696317  [ 6464/60000]\n",
      "loss: 0.473054  [12864/60000]\n",
      "loss: 0.729365  [19264/60000]\n",
      "loss: 0.666930  [25664/60000]\n",
      "loss: 0.626679  [32064/60000]\n",
      "loss: 0.715727  [38464/60000]\n",
      "loss: 0.699001  [44864/60000]\n",
      "loss: 0.695937  [51264/60000]\n",
      "loss: 0.671707  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.661481 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.578775  [   64/60000]\n",
      "loss: 0.686754  [ 6464/60000]\n",
      "loss: 0.459940  [12864/60000]\n",
      "loss: 0.718968  [19264/60000]\n",
      "loss: 0.657096  [25664/60000]\n",
      "loss: 0.612584  [32064/60000]\n",
      "loss: 0.701625  [38464/60000]\n",
      "loss: 0.690600  [44864/60000]\n",
      "loss: 0.690024  [51264/60000]\n",
      "loss: 0.661554  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.651386 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.563368  [   64/60000]\n",
      "loss: 0.678956  [ 6464/60000]\n",
      "loss: 0.449213  [12864/60000]\n",
      "loss: 0.709191  [19264/60000]\n",
      "loss: 0.648506  [25664/60000]\n",
      "loss: 0.600435  [32064/60000]\n",
      "loss: 0.688574  [38464/60000]\n",
      "loss: 0.683327  [44864/60000]\n",
      "loss: 0.685578  [51264/60000]\n",
      "loss: 0.652207  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.642342 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.550259  [   64/60000]\n",
      "loss: 0.672387  [ 6464/60000]\n",
      "loss: 0.440203  [12864/60000]\n",
      "loss: 0.699855  [19264/60000]\n",
      "loss: 0.640979  [25664/60000]\n",
      "loss: 0.589801  [32064/60000]\n",
      "loss: 0.676454  [38464/60000]\n",
      "loss: 0.677012  [44864/60000]\n",
      "loss: 0.682164  [51264/60000]\n",
      "loss: 0.643451  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.634130 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.538955  [   64/60000]\n",
      "loss: 0.666684  [ 6464/60000]\n",
      "loss: 0.432445  [12864/60000]\n",
      "loss: 0.690882  [19264/60000]\n",
      "loss: 0.634345  [25664/60000]\n",
      "loss: 0.580393  [32064/60000]\n",
      "loss: 0.665169  [38464/60000]\n",
      "loss: 0.671545  [44864/60000]\n",
      "loss: 0.679482  [51264/60000]\n",
      "loss: 0.635141  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.626604 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.529079  [   64/60000]\n",
      "loss: 0.661595  [ 6464/60000]\n",
      "loss: 0.425619  [12864/60000]\n",
      "loss: 0.682245  [19264/60000]\n",
      "loss: 0.628447  [25664/60000]\n",
      "loss: 0.572009  [32064/60000]\n",
      "loss: 0.654638  [38464/60000]\n",
      "loss: 0.666852  [44864/60000]\n",
      "loss: 0.677312  [51264/60000]\n",
      "loss: 0.627176  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.619667 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.520341  [   64/60000]\n",
      "loss: 0.656941  [ 6464/60000]\n",
      "loss: 0.419500  [12864/60000]\n",
      "loss: 0.673934  [19264/60000]\n",
      "loss: 0.623144  [25664/60000]\n",
      "loss: 0.564492  [32064/60000]\n",
      "loss: 0.644794  [38464/60000]\n",
      "loss: 0.662873  [44864/60000]\n",
      "loss: 0.675490  [51264/60000]\n",
      "loss: 0.619480  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.613246 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.512512  [   64/60000]\n",
      "loss: 0.652591  [ 6464/60000]\n",
      "loss: 0.413933  [12864/60000]\n",
      "loss: 0.665948  [19264/60000]\n",
      "loss: 0.618309  [25664/60000]\n",
      "loss: 0.557711  [32064/60000]\n",
      "loss: 0.635579  [38464/60000]\n",
      "loss: 0.659559  [44864/60000]\n",
      "loss: 0.673881  [51264/60000]\n",
      "loss: 0.611992  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.607282 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.505409  [   64/60000]\n",
      "loss: 0.648447  [ 6464/60000]\n",
      "loss: 0.408804  [12864/60000]\n",
      "loss: 0.658283  [19264/60000]\n",
      "loss: 0.613825  [25664/60000]\n",
      "loss: 0.551552  [32064/60000]\n",
      "loss: 0.626941  [38464/60000]\n",
      "loss: 0.656858  [44864/60000]\n",
      "loss: 0.672378  [51264/60000]\n",
      "loss: 0.604666  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.601725 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.498879  [   64/60000]\n",
      "loss: 0.644434  [ 6464/60000]\n",
      "loss: 0.404030  [12864/60000]\n",
      "loss: 0.650932  [19264/60000]\n",
      "loss: 0.609593  [25664/60000]\n",
      "loss: 0.545910  [32064/60000]\n",
      "loss: 0.618838  [38464/60000]\n",
      "loss: 0.654717  [44864/60000]\n",
      "loss: 0.670893  [51264/60000]\n",
      "loss: 0.597464  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.596531 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.492797  [   64/60000]\n",
      "loss: 0.640496  [ 6464/60000]\n",
      "loss: 0.399553  [12864/60000]\n",
      "loss: 0.643884  [19264/60000]\n",
      "loss: 0.605529  [25664/60000]\n",
      "loss: 0.540692  [32064/60000]\n",
      "loss: 0.611229  [38464/60000]\n",
      "loss: 0.653079  [44864/60000]\n",
      "loss: 0.669358  [51264/60000]\n",
      "loss: 0.590361  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.591659 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.487057  [   64/60000]\n",
      "loss: 0.636592  [ 6464/60000]\n",
      "loss: 0.395325  [12864/60000]\n",
      "loss: 0.637124  [19264/60000]\n",
      "loss: 0.601568  [25664/60000]\n",
      "loss: 0.535815  [32064/60000]\n",
      "loss: 0.604075  [38464/60000]\n",
      "loss: 0.651882  [44864/60000]\n",
      "loss: 0.667723  [51264/60000]\n",
      "loss: 0.583339  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.587069 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.481572  [   64/60000]\n",
      "loss: 0.632694  [ 6464/60000]\n",
      "loss: 0.391311  [12864/60000]\n",
      "loss: 0.630634  [19264/60000]\n",
      "loss: 0.597658  [25664/60000]\n",
      "loss: 0.531213  [32064/60000]\n",
      "loss: 0.597344  [38464/60000]\n",
      "loss: 0.651066  [44864/60000]\n",
      "loss: 0.665953  [51264/60000]\n",
      "loss: 0.576391  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.582727 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.476271  [   64/60000]\n",
      "loss: 0.628784  [ 6464/60000]\n",
      "loss: 0.387485  [12864/60000]\n",
      "loss: 0.624394  [19264/60000]\n",
      "loss: 0.593765  [25664/60000]\n",
      "loss: 0.526829  [32064/60000]\n",
      "loss: 0.591001  [38464/60000]\n",
      "loss: 0.650572  [44864/60000]\n",
      "loss: 0.664025  [51264/60000]\n",
      "loss: 0.569513  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.578602 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.471097  [   64/60000]\n",
      "loss: 0.624850  [ 6464/60000]\n",
      "loss: 0.383822  [12864/60000]\n",
      "loss: 0.618383  [19264/60000]\n",
      "loss: 0.589864  [25664/60000]\n",
      "loss: 0.522619  [32064/60000]\n",
      "loss: 0.585019  [38464/60000]\n",
      "loss: 0.650344  [44864/60000]\n",
      "loss: 0.661929  [51264/60000]\n",
      "loss: 0.562710  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.574666 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.466005  [   64/60000]\n",
      "loss: 0.620889  [ 6464/60000]\n",
      "loss: 0.380303  [12864/60000]\n",
      "loss: 0.612583  [19264/60000]\n",
      "loss: 0.585941  [25664/60000]\n",
      "loss: 0.518553  [32064/60000]\n",
      "loss: 0.579369  [38464/60000]\n",
      "loss: 0.650333  [44864/60000]\n",
      "loss: 0.659665  [51264/60000]\n",
      "loss: 0.555987  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.570896 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.460962  [   64/60000]\n",
      "loss: 0.616900  [ 6464/60000]\n",
      "loss: 0.376908  [12864/60000]\n",
      "loss: 0.606973  [19264/60000]\n",
      "loss: 0.581987  [25664/60000]\n",
      "loss: 0.514608  [32064/60000]\n",
      "loss: 0.574025  [38464/60000]\n",
      "loss: 0.650495  [44864/60000]\n",
      "loss: 0.657236  [51264/60000]\n",
      "loss: 0.549355  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.567272 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.455945  [   64/60000]\n",
      "loss: 0.612884  [ 6464/60000]\n",
      "loss: 0.373621  [12864/60000]\n",
      "loss: 0.601539  [19264/60000]\n",
      "loss: 0.577999  [25664/60000]\n",
      "loss: 0.510769  [32064/60000]\n",
      "loss: 0.568963  [38464/60000]\n",
      "loss: 0.650788  [44864/60000]\n",
      "loss: 0.654653  [51264/60000]\n",
      "loss: 0.542826  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.563776 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.450939  [   64/60000]\n",
      "loss: 0.608847  [ 6464/60000]\n",
      "loss: 0.370425  [12864/60000]\n",
      "loss: 0.596263  [19264/60000]\n",
      "loss: 0.573974  [25664/60000]\n",
      "loss: 0.507026  [32064/60000]\n",
      "loss: 0.564163  [38464/60000]\n",
      "loss: 0.651179  [44864/60000]\n",
      "loss: 0.651930  [51264/60000]\n",
      "loss: 0.536411  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.560394 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.445936  [   64/60000]\n",
      "loss: 0.604794  [ 6464/60000]\n",
      "loss: 0.367306  [12864/60000]\n",
      "loss: 0.591135  [19264/60000]\n",
      "loss: 0.569915  [25664/60000]\n",
      "loss: 0.503377  [32064/60000]\n",
      "loss: 0.559605  [38464/60000]\n",
      "loss: 0.651637  [44864/60000]\n",
      "loss: 0.649081  [51264/60000]\n",
      "loss: 0.530124  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.557114 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.440934  [   64/60000]\n",
      "loss: 0.600732  [ 6464/60000]\n",
      "loss: 0.364250  [12864/60000]\n",
      "loss: 0.586142  [19264/60000]\n",
      "loss: 0.565822  [25664/60000]\n",
      "loss: 0.499818  [32064/60000]\n",
      "loss: 0.555269  [38464/60000]\n",
      "loss: 0.652135  [44864/60000]\n",
      "loss: 0.646121  [51264/60000]\n",
      "loss: 0.523978  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.553927 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.435935  [   64/60000]\n",
      "loss: 0.596670  [ 6464/60000]\n",
      "loss: 0.361244  [12864/60000]\n",
      "loss: 0.581276  [19264/60000]\n",
      "loss: 0.561698  [25664/60000]\n",
      "loss: 0.496351  [32064/60000]\n",
      "loss: 0.551140  [38464/60000]\n",
      "loss: 0.652648  [44864/60000]\n",
      "loss: 0.643068  [51264/60000]\n",
      "loss: 0.517985  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.550825 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#2 layer 37 epoch\n",
    "#2 Layer rr_footprint: 30\n",
    "#2 layer rr_layer: 27 epoch\n",
    "t, acc = 0, 0\n",
    "while acc < 80:\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    acc = test(test_dataloader, model, loss_fn) * 100\n",
    "    t += 1\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state = model.state_dict()\n",
    "new_state[\"linear_relu_stack.4.weight\"] = pooled_rr_footprint\n",
    "model.load_state_dict(new_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
